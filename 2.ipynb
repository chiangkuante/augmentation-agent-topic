{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37898803",
   "metadata": {},
   "source": [
    "# 第二階段：初始主題生成（BERTopic）\n",
    "\n",
    "- 嵌入模型：OpenAI **text-3-small**（1536 維）\n",
    "- 降維：UMAP，聚類：HDBSCAN，表示：c-TF-IDF（BERTopic）\n",
    "- 輸出：\n",
    "  - `/mnt/data/part2_bertopic_model/`（可供後續載入）\n",
    "  - `/mnt/data/part2_topics.csv`（主題概覽）\n",
    "  - `/mnt/data/part2_doc_topic_probs.npy`（doc×topic 機率）\n",
    "  - `/mnt/data/part2_corpus_with_topics.csv`（語料含 topic）\n",
    "\n",
    "> 執行前請先設定環境變數 `OPENAI_API_KEY`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7772c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一次執行請取消註解安裝依賴，裝完重啟 kernel\n",
    "# %pip install pandas numpy tqdm plotly umap-learn hdbscan bertopic openai==1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "CSV_PATH = Path('/mnt/data/corpus.csv')\n",
    "assert CSV_PATH.exists(), '找不到 /mnt/data/corpus.csv'\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "assert 'text' in df.columns, \"語料需要包含 'text' 欄位\"\n",
    "meta_cols = [c for c in ['doc_id','company','firm','ticker','year','date'] if c in df.columns]\n",
    "print('偵測到 metadata 欄位：', meta_cols or '(無)')\n",
    "\n",
    "client = OpenAI()  # 需先設 OPENAI_API_KEY\n",
    "MODEL_EMB = 'text-3-small'\n",
    "EMB_PATH = Path('/mnt/data/embeddings_text-3-small.npy')\n",
    "IDX_PATH = Path('/mnt/data/embeddings_index.json')\n",
    "texts = df['text'].astype(str).tolist()\n",
    "\n",
    "if EMB_PATH.exists() and IDX_PATH.exists():\n",
    "    embeddings = np.load(EMB_PATH)\n",
    "else:\n",
    "    BATCH=256\n",
    "    vecs=[]\n",
    "    for i in tqdm(range(0,len(texts),BATCH)):\n",
    "        batch=texts[i:i+BATCH]\n",
    "        r=client.embeddings.create(model=MODEL_EMB, input=batch)\n",
    "        vecs.extend([np.array(d.embedding, dtype=np.float32) for d in r.data])\n",
    "    embeddings=np.vstack(vecs)\n",
    "    np.save(EMB_PATH, embeddings)\n",
    "    with open(IDX_PATH,'w') as f: json.dump({'count':len(texts),'model':MODEL_EMB},f)\n",
    "print('embeddings shape:', embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "import hdbscan\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=10, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=30, min_samples=10, metric='euclidean',\n",
    "                                 cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "topic_model = BERTopic(calculate_probabilities=True, verbose=True,\n",
    "                       umap_model=umap_model, hdbscan_model=hdbscan_model)\n",
    "topics, probs = topic_model.fit_transform(texts, embeddings=embeddings)\n",
    "df['topic'] = topics\n",
    "topic_info = topic_model.get_topic_info(); topic_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57978d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path('/mnt/data/part2_bertopic_model'); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "topic_model.save(OUT_DIR.as_posix())\n",
    "topic_info.to_csv('/mnt/data/part2_topics.csv', index=False, encoding='utf-8')\n",
    "if probs is not None:\n",
    "    np.save('/mnt/data/part2_doc_topic_probs.npy', probs)\n",
    "df.to_csv('/mnt/data/part2_corpus_with_topics.csv', index=False, encoding='utf-8')\n",
    "print('已輸出 part2_bertopic_model / part2_topics.csv / part2_doc_topic_probs.npy / part2_corpus_with_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_barchart(top_n_topics=20); fig.show()\n",
    "fig = topic_model.visualize_hierarchy(top_n_topics=50); fig.show()\n",
    "fig = topic_model.visualize_topics(); fig.show()\n",
    "\n",
    "if 'year' in df.columns:\n",
    "    year_dist = df.groupby('year')['topic'].value_counts(normalize=True).rename('prop').reset_index()\n",
    "    year_dist.to_csv('/mnt/data/part2_topic_prop_by_year.csv', index=False, encoding='utf-8')\n",
    "    year_dist.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
